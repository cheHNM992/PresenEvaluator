{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444d16ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# プレゼン評価システム\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pptx\n",
    "import openai\n",
    "import numpy as np\n",
    "import base64\n",
    "from pptx import Presentation\n",
    "from pptx.enum.shapes import MSO_SHAPE_TYPE\n",
    "from datetime import datetime\n",
    "\n",
    "# ==== 設定 ====\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-proj-*****'  # ご自身のAPIキーに置き換えてください\n",
    "model_llm = \"gpt-5\"\n",
    "#model_llm = \"gpt-5-nano\"\n",
    "model_whisper = \"whisper-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e99510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 音声分析モジュール ====\n",
    "def transcribe_audio(file_path):\n",
    "    audio_file = open(file_path, \"rb\")\n",
    "    response = openai.audio.transcriptions.create(\n",
    "        model=model_whisper,\n",
    "        file=audio_file,\n",
    "        response_format=\"verbose_json\",\n",
    "        language=\"ja\"\n",
    "    )\n",
    "\n",
    "    text = response.text\n",
    "    segments = response.segments\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"transcription_{timestamp}.txt\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "    return text, segments\n",
    "\n",
    "\n",
    "def analyze_speech(segments):\n",
    "    total_words = sum(len(seg.text.split()) for seg in segments)\n",
    "    duration_minutes = (segments[-1].end - segments[0].start) / 60.0\n",
    "    wpm = total_words / duration_minutes if duration_minutes else 0\n",
    "\n",
    "    filler_words = ['えーと', 'あの', 'えっと', 'その']\n",
    "    filler_count = sum(sum(word in seg.text for word in filler_words) for seg in segments)\n",
    "\n",
    "    pause_lengths = [segments[i + 1].start - segments[i].end for i in range(len(segments) - 1)]\n",
    "    long_pauses = sum(1 for p in pause_lengths if p > 1.0)\n",
    "\n",
    "    return {\n",
    "        \"wpm\": round(wpm, 2),\n",
    "        \"filler_count\": filler_count,\n",
    "        \"long_pauses\": long_pauses\n",
    "    }\n",
    "\n",
    "\n",
    "# ==== 資料抽出モジュール ====\n",
    "def extract_ppt_text(file_path):\n",
    "    prs = Presentation(file_path)\n",
    "    slides_text = []\n",
    "    for i, slide in enumerate(prs.slides):\n",
    "        slide_text = \"\\n\".join([shape.text for shape in slide.shapes if hasattr(shape, \"text\")])\n",
    "        slides_text.append(f\"スライド {i + 1}:\\n{slide_text}\\n\")\n",
    "    return \"\\n\".join(slides_text)\n",
    "\n",
    "\n",
    "def extract_images_from_ppt(ppt_path, output_dir):\n",
    "    prs = Presentation(ppt_path)\n",
    "    image_files = []\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for i, slide in enumerate(prs.slides):\n",
    "        for j, shape in enumerate(slide.shapes):\n",
    "            if shape.shape_type == MSO_SHAPE_TYPE.PICTURE:\n",
    "                image = shape.image\n",
    "                image_bytes = image.blob\n",
    "                image_filename = os.path.join(output_dir, f\"slide_{i + 1}_image_{j + 1}.png\")\n",
    "                with open(image_filename, 'wb') as f:\n",
    "                    f.write(image_bytes)\n",
    "                image_files.append(image_filename)\n",
    "\n",
    "    return image_files\n",
    "\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "def analyze_image(image_path):\n",
    "    base64_image = encode_image_to_base64(image_path)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model_llm,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"あなたは画像解析の専門家です。\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"この画像に何が写っているか説明し、プレゼン資料として適切か評価してください。視覚資料としての質も100点満点（整数）で採点してください。フォーマット: 視覚資料: ○点\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def extract_visual_score(image_analysis):\n",
    "    pattern = r\"視覚資料: ([0-9]{1,3})点\"\n",
    "    matches = re.findall(pattern, image_analysis)\n",
    "    if matches:\n",
    "        scores = [int(score) for score in matches] # Convert to int\n",
    "        return int(sum(scores) / len(scores)) # Return as int\n",
    "    return 0\n",
    "\n",
    "\n",
    "def analyze_all_images(image_files):\n",
    "    all_analyses = []\n",
    "    for image_path in image_files:\n",
    "        analysis = analyze_image(image_path)\n",
    "        all_analyses.append(f\"{image_path}:\\n{analysis}\\n\")\n",
    "    return \"\\n\".join(all_analyses)\n",
    "\n",
    "\n",
    "def analyze_slide_text(slide_text):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model_llm,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"あなたはプロのプレゼン資料評価者です。\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "以下はプレゼンテーションのスライド全文です。\n",
    "\n",
    "[スライド全文]\n",
    "{slide_text}\n",
    "\n",
    "この資料のスライド数、各スライドの文字量の適切さ、内容を評価し、全体的な資料の質を以下のフォーマットで100点満点（整数）で評価してください。\n",
    "ただし、図表や画像は評価に含めないでください。\n",
    "\n",
    "資料: ○点\n",
    "\n",
    "その後に資料の良い点と改善点を簡単にまとめてください。\n",
    "\"\"\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def generate_evaluation_with_images(transcription, slide_text_analysis, image_analysis):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model_llm,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"あなたはプロのプレゼン評価者です。\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "以下はプレゼンの文字起こしとスライド資料の分析結果、および画像分析結果です。\n",
    "\n",
    "[文字起こし]:\n",
    "{transcription}\n",
    "\n",
    "[スライドテキスト分析]:\n",
    "{slide_text_analysis}\n",
    "\n",
    "[画像分析]:\n",
    "{image_analysis}\n",
    "\n",
    "以下の4つの観点（内容、プレゼン技術、視覚資料、構成）について、それぞれ100点満点（整数）で評価し、簡単な理由と改善点、長所を出力してください。\n",
    "最後に3つの改善点と具体的なアドバイスも示してください。\n",
    "\n",
    "フォーマットは必ず以下としてください：\n",
    "内容: ○点\n",
    "プレゼン技術: ○点\n",
    "視覚資料: ○点\n",
    "構成: ○点\n",
    "\n",
    "その後に評価コメントを書いてください。\n",
    "\"\"\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# ==== スコア抽出 ====\n",
    "def extract_scores(evaluation_text):\n",
    "    pattern = r\"内容: ([0-9]{1,3})点.*?プレゼン技術: ([0-9]{1,3})点.*?視覚資料: ([0-9]{1,3})点.*?構成: ([0-9]{1,3})点\"\n",
    "    match = re.search(pattern, evaluation_text, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        return {\n",
    "            \"内容\": int(match.group(1)),  # Convert to int\n",
    "            \"プレゼン技術\": int(match.group(2)), # Convert to int\n",
    "            \"視覚資料\": int(match.group(3)), # Convert to int\n",
    "            \"構成\": int(match.group(4))  # Convert to int\n",
    "        }\n",
    "    else:\n",
    "        print(\"スコアの抽出に失敗しました。デフォルトで全て0点とします。\")\n",
    "        return {\n",
    "            \"内容\": 0,\n",
    "            \"プレゼン技術\": 0,\n",
    "            \"視覚資料\": 0,\n",
    "            \"構成\": 0\n",
    "        }\n",
    "\n",
    "\n",
    "# ==== スコア集計 ====\n",
    "def compute_score(sub_scores):\n",
    "    weights = {\n",
    "        \"内容\": 0.3,\n",
    "        \"プレゼン技術\": 0.3,\n",
    "        \"視覚資料\": 0.2,\n",
    "        \"構成\": 0.2\n",
    "    }\n",
    "    total = sum(float(sub_scores[k]) * weights[k] for k in weights)\n",
    "    return int(round(total, 0)) # Round to nearest integer and cast to int\n",
    "\n",
    "\n",
    "# ==== プレゼン評価処理 ====\n",
    "def evaluate_presentation(audio_path, ppt_path):\n",
    "    print(f\"音声分析中\")\n",
    "    text, segments = transcribe_audio(audio_path)\n",
    "    speech_analysis = analyze_speech(segments)\n",
    "\n",
    "    print(f\"資料分析中\")\n",
    "    slides_text = extract_ppt_text(ppt_path)\n",
    "    slide_text_analysis = analyze_slide_text(slides_text)\n",
    "\n",
    "    print(f\"画像解析中\")\n",
    "    image_files = extract_images_from_ppt(ppt_path, \"extracted_images\")\n",
    "    if image_files:\n",
    "        image_analysis = analyze_all_images(image_files)\n",
    "        image_visual_score = extract_visual_score(image_analysis)\n",
    "    else:\n",
    "        image_analysis = \"画像は含まれていません。\"\n",
    "        image_visual_score = 0\n",
    "\n",
    "    evaluation = generate_evaluation_with_images(text, slide_text_analysis, image_analysis)\n",
    "\n",
    "    sub_scores = extract_scores(evaluation)\n",
    "    sub_scores[\"視覚資料\"] = int(round((sub_scores[\"視覚資料\"] + image_visual_score) / 2, 0))\n",
    "\n",
    "    total_score = compute_score(sub_scores)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    result_filename = f\"evaluation_result_{timestamp}.txt\"\n",
    "\n",
    "    with open(result_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"==== 総合得点: {total_score}点 ====\\n\\n\")\n",
    "        f.write(\"==== 総合評価 ====\\n\")\n",
    "        f.write(evaluation + \"\\n\\n\")\n",
    "        f.write(\"==== 音声分析 ====\\n\")\n",
    "        f.write(str(speech_analysis) + \"\\n\\n\")\n",
    "#        f.write(\"==== スライドテキスト分析 ====\\n\")    #テキストのみの分析結果とならないため非表示\n",
    "#        f.write(slide_text_analysis + \"\\n\\n\")\n",
    "#        f.write(\"==== 画像分析 ====\\n\")               #冗長な結果しか出力できないため非表示\n",
    "#        f.write(image_analysis + \"\\n\\n\")\n",
    "\n",
    "    print(f\"\\n評価結果をファイルに保存しました: {result_filename}\")\n",
    "\n",
    "    # 画像ファイル自動削除\n",
    "    if image_files:\n",
    "        for image_path in image_files:\n",
    "            os.remove(image_path)\n",
    "        os.rmdir(\"extracted_images\")\n",
    "        print(\"\\n一時画像ファイルを削除しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"data/202507_honma.m4a\"\n",
    "ppt_path = \"data/202507_honma.pptx\"\n",
    "\n",
    "if not os.path.exists(audio_path):\n",
    "    print(f\"音声ファイルが見つかりません: {audio_path}\")\n",
    "    sys.exit(1)\n",
    "if not os.path.exists(ppt_path):\n",
    "    print(f\"PowerPointファイルが見つかりません: {ppt_path}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "evaluate_presentation(audio_path, ppt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
